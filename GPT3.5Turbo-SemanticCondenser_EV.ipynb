{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d823eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucid\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lucid\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\lucid\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Model model id=gpt-3.5-turbo at 0x1d97f9e74a0> JSON: {\n",
       "  \"created\": 1677610602,\n",
       "  \"id\": \"gpt-3.5-turbo\",\n",
       "  \"object\": \"model\",\n",
       "  \"owned_by\": \"openai\",\n",
       "  \"parent\": null,\n",
       "  \"permission\": [\n",
       "    {\n",
       "      \"allow_create_engine\": false,\n",
       "      \"allow_fine_tuning\": false,\n",
       "      \"allow_logprobs\": true,\n",
       "      \"allow_sampling\": true,\n",
       "      \"allow_search_indices\": false,\n",
       "      \"allow_view\": true,\n",
       "      \"created\": 1683852530,\n",
       "      \"group\": null,\n",
       "      \"id\": \"modelperm-C34BeeteYvuLNoa893aJRcnp\",\n",
       "      \"is_blocking\": false,\n",
       "      \"object\": \"model_permission\",\n",
       "      \"organization\": \"*\"\n",
       "    }\n",
       "  ],\n",
       "  \"root\": \"gpt-3.5-turbo\"\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time \n",
    "import pdfkit\n",
    "import re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "openai.organization = os.environ.get(\"OPENAI_ORGANIZATION\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "openai.Model.retrieve('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c50af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_csv('ExplodedPositivesEV.csv').dropna()\n",
    "dfn = pd.read_csv('ExplodedNegativesEV.csv').dropna()\n",
    "dfw = pd.read_csv('ExplodedWishlistEV.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5e0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_condenser2(df, context):\n",
    "    master_list = []\n",
    "    index_exceptions = []\n",
    "    #Taking 500 first pass features at a time to stay with 4096 context length\n",
    "\n",
    "    features = df[\"Features\"].tolist()\n",
    "    ft = len(features)\n",
    "    #Accounting for number of features under 500, between the exact multiples of 500 etc. \n",
    "    qt = len(features) // context\n",
    "    rem = len(features) % context\n",
    "    if rem == 0:\n",
    "        iterations = qt\n",
    "    else:\n",
    "        iterations = qt + 1\n",
    "    ind = 0\n",
    "    if qt == 0:\n",
    "        ind2 = len(features)\n",
    "    else:\n",
    "        ind2 = context\n",
    "        #print('Model: ', i)\n",
    "        #print('Model Occurences: ', ft)\n",
    "        #print('Iterations', iterations)\n",
    "    for j in tqdm(range(iterations)):\n",
    "        try:\n",
    "            content = openai.ChatCompletion.create(\n",
    "            model = 'gpt-3.5-turbo',\n",
    "            messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that performs the specific task being asked.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Given a list of words in the following list which contain many words with similar semantic \"\\\n",
    "         \"meaning, condense those words into a smaller list of words which represent the same meaning. The words are related to \"\\\n",
    "         \"vehicle features. Make each word or feature into a bullet point. Focus purely on vehicle features like Fuel Efficiency, Spacious Interiors etc. \"\\\n",
    "         \"Try to make each feature as distinct as possible from the others. If similar, try to group them together into a \"\\\n",
    "         \"single feature. Avoid long bullet points. Do not number the bullets. Do not add anything else to the response like \"\\\n",
    "         \"a Note or a warning. List:  \" + (', ').join(features[ind:ind2])}\n",
    "         ],\n",
    "        temperature = 1,\n",
    "        max_tokens= 1000,\n",
    "        frequency_penalty = 0,\n",
    "        presence_penalty = 0.9,\n",
    "        #n=3\n",
    "            ).get(\"choices\")[0]['message']['content'].split('\\n')\n",
    "        \n",
    "            ret = [x.replace('- ', '') for x in content]\n",
    "        \n",
    "        #Chaining and further compression at this stage does not work well. It seems to ignore making each word/feature into a \n",
    "        #separate bullet and instead uses and to group them together which isn't what we want.\n",
    "        #content2 = openai.ChatCompletion.create(\n",
    "        #    model = 'gpt-3.5-turbo',\n",
    "        #    messages=[\n",
    "        #{\"role\": \"system\", \"content\": \"You are a helpful assistant that performs the specific task being asked.\"},\n",
    "        #{\"role\": \"user\", \"content\": \"Given a list of words in the following list which contain many words with similar semantic \"\\\n",
    "        # \"meaning, condense those words into a smaller list of words which represent the same meaning. The words are related to \"\\\n",
    "        # \"vehicle features. Do not add anything else to the response. Make each word or feature into a bullet point. \"\\\n",
    "        # \"Try to make each feature as distinct as possible from the others. If similar, try to group them together into a \"\\\n",
    "        # \"single feature. List:  \" + (', ').join(ret)}\n",
    "        # ],\n",
    "        #temperature = 1,\n",
    "        #max_tokens= 1000,\n",
    "        #frequency_penalty = 0,\n",
    "        #presence_penalty = 0.9,\n",
    "        #n=3\n",
    "        #    ).get(\"choices\")[0]['message']['content'].split('\\n')\n",
    "        \n",
    "        #ret2 = [x.replace('- ', '') for x in content2]\n",
    "                #print('Index1: ', ind)\n",
    "                #print('Index2: ', ind2)\n",
    "            ind = ind + context\n",
    "            if (ind2 + context) > ft:\n",
    "                ind2 = ft\n",
    "            else:\n",
    "                ind2 =  ind2 + context\n",
    "            master_list.append(ret)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            index_exceptions.append((ind, ind2))\n",
    "            continue\n",
    "\n",
    "        \n",
    "    #Conversion into a data format that's identical to the orginal input. i.e, a dataframe with relevant column names and no \n",
    "    #nested data structures. \n",
    "    master_list2 = []\n",
    "    for i in master_list:\n",
    "        master_list2.append(', '.join(i))\n",
    "    level1 = pd.DataFrame(master_list2, columns = [\"Features\"])\n",
    "    level1e = pd.DataFrame(level1.assign(Features = level1['Features'].str.split(',')).explode('Features'))\n",
    "    #level1e = pd.DataFrame(level1e.assign(Features = level1e['Features'].str.split(' and ')).explode('Features')) \n",
    "    level1e = pd.DataFrame(level1e.assign(Features = level1e['Features'].str.split('/')).explode('Features')) \n",
    "    level1e['Word Count'] = level1e['Features'].str.split(' ').str.len()\n",
    "    level1e = level1e.drop_duplicates()\n",
    "    return (level1e, index_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40aac4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [24:25<00:00, 19.80s/it]\n"
     ]
    }
   ],
   "source": [
    "level1_masterp = semantic_condenser2(dfp, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80a5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_masterpos = level1_masterp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4a2cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▍                                                     | 42/124 [13:59<22:01, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fdaa987b27c5b75564efeb9a3c14ee65 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▉                                | 75/124 [25:39<20:54, 25.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8df6a7a9565b4c52dd6dc6a09b428528 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [44:42<00:00, 21.64s/it]\n"
     ]
    }
   ],
   "source": [
    "level1_mastern = semantic_condenser2(dfn, 250)\n",
    "level1_masterneg = level1_mastern[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2247e3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                              Features  Word Count\n",
       " 0                       Shorter Range than Competitors           4\n",
       " 0                                          Feels Heavy           3\n",
       " 0                                               Pricey           2\n",
       " 0              Poor gas mileage for a car of this type          10\n",
       " 0                           Poor response from Genesis           5\n",
       " ..                                                 ...         ...\n",
       " 121   Limited availability of Class 3 charging stat...          11\n",
       " 121                              Terrible resale value           4\n",
       " 121                          Bad fuel efficiency (mpg)           5\n",
       " 121   Limited selection of vehicles with desired fe...           9\n",
       " 121                         Extremely sensitive system           4\n",
       " \n",
       " [4944 rows x 2 columns],\n",
       " [(10250, 10500), (18250, 18500)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1_mastern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16b5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                                | 10/46 [05:12<17:59, 29.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a4d43c41ca0e4ec2024c4dc6d9882612 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                         | 14/46 [07:11<15:36, 29.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5b97d4b9e7b2f790e2809757a296886d in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [26:48<00:00, 34.96s/it]\n"
     ]
    }
   ],
   "source": [
    "level1_masterw = semantic_condenser2(dfw, 250)\n",
    "level1_masterwish = level1_masterw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95000ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [05:27<00:00, 27.28s/it]\n"
     ]
    }
   ],
   "source": [
    "level2_masterp = semantic_condenser2(level1_masterpos, 300)\n",
    "level2_masterpos = level2_masterp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7907f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [07:36<00:00, 26.87s/it]\n"
     ]
    }
   ],
   "source": [
    "level2_mastern = semantic_condenser2(level1_masterneg, 300)\n",
    "level2_masterneg = level2_mastern[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8eb234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:49<00:00, 31.81s/it]\n"
     ]
    }
   ],
   "source": [
    "level2_masterw = semantic_condenser2(level1_masterwish, 300)\n",
    "level2_masterwish = level2_masterw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4a1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:28<00:00, 49.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:48<00:00, 16.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:15<00:00, 45.18s/it]\n"
     ]
    }
   ],
   "source": [
    "level3_masterp = semantic_condenser2(level2_masterpos, 300)\n",
    "level3_mastern = semantic_condenser2(level2_masterneg, 300)\n",
    "level3_masterw = semantic_condenser2(level2_masterwish, 300)\n",
    "level3_masterpos = level3_masterp[0]\n",
    "level3_masterneg = level3_mastern[0]\n",
    "level3_masterwish = level3_masterw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9ff7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:13<00:00, 73.45s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:13<00:00, 73.89s/it]\n"
     ]
    }
   ],
   "source": [
    "#Level4 can be used in this case as the final condensed list as it completely avoids overlap\n",
    "level4_masterp = semantic_condenser2(level3_masterpos, 300)\n",
    "level4_mastern = semantic_condenser2(level3_masterneg, 300)\n",
    "level4_masterw = semantic_condenser2(level3_masterwish, 300)\n",
    "level4_masterpos = level4_masterp[0]\n",
    "level4_masterneg = level4_mastern[0]\n",
    "level4_masterwish = level4_masterw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "level4_masterpos.to_csv('CondensedPositivesEV_L4.csv')\n",
    "level4_masterneg.to_csv('CondensedNegativesEV_L4.csv')\n",
    "level4_masterwish.to_csv('CondensedWishlistEV_L4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
